# Project Requirements Document: DeepResearcher AI Agent (Proof of Concept for Hackathon)

**Version:** 0.1.0
**Date:** April 12, 2025

## Detailed Requirements (User Stories)

| ID      | Short Description             | User Story                                                     | Expected Behaviour / Outcome                                                                                                                                                                                             |
| :------ | :---------------------------- | :------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **S1-R1** | Basic User Interface        | As a user, I want a simple text input field and a display area so that I can ask questions and see the AI's responses. | A clean web interface with a text input box for queries and a designated area where AI responses will be displayed in a chat-like format.                                                              |
| **S1-R2** | Send User Query             | As a user, I want to be able to type a question and send it to the AI system. | When the user enters text and submits (e.g., by pressing Enter or a button), the text query is sent to the backend API.                                                                                             |
| **S1-R3** | Receive AI Response         | As a user, I want to see the AI's answer to my question displayed in the UI. | The AI's response, received from the backend, is displayed clearly in the designated area of the user interface, associated with the user's original query.                                                    |
| **S1-R4** | Backend API Endpoint (Query) | As a developer, I need a backend API endpoint to receive user text queries. | A REST API endpoint (e.g., `/api/query` using POST method) is available on the backend, capable of receiving text-based user queries.                                                                            |
| **S2-R1** | File Upload Functionality   | As a user, I want to be able to upload PDF research papers to the system. | A file upload mechanism (e.g., a button or drag-and-drop area) is present in the UI, allowing users to select and upload PDF files.                                                                                  |
| **S2-R2** | Backend API Endpoint (Upload) | As a developer, I need a backend API endpoint to receive uploaded files. | A REST API endpoint (e.g., `/api/upload` using POST method with appropriate multipart/form-data handling) is available on the backend, capable of receiving uploaded files.                                       |
| **S2-R3** | PDF Text Extraction         | As a developer, the system should extract text content from uploaded PDF files. | Upon successful file upload, the backend processes the PDF file and extracts its textual content.                                                                                                                 |
| **S2-R4** | Basic Document Chunking     | As a developer, the extracted text should be divided into smaller segments or chunks. | The extracted text is split into manageable chunks based on a simple strategy (e.g., fixed character length or paragraph breaks).                                                                               |
| **S3-R1** | Generate Embeddings         | As a developer, the system should generate vector embeddings for each text chunk. | Each text chunk is processed by an embedding model (e.g., via Azure OpenAI Service), and a corresponding vector embedding is created.                                                                             |
| **S3-R2** | Store Embeddings            | As a developer, the generated embeddings should be stored for efficient searching. | The generated vector embeddings, along with the corresponding text chunks and metadata linking them to the original document, are stored in a suitable data store (e.g., Azure Cognitive Search - Free Tier). |
| **S3-R3** | Vectorize User Query        | As a developer, the user's text query should be converted into a vector embedding. | When a user submits a query, the same embedding model used for document chunks is used to generate a vector embedding for the query text.                                                                    |
| **S3-R4** | Basic Semantic Search       | As a developer, the system should retrieve relevant document chunks based on the semantic similarity of the user query. | The vector embedding of the user query is used to perform a similarity search against the stored document embeddings, and the top N most similar chunks are retrieved.                                     |
| **S4-R1** | Retrieve Relevant Context   | As a developer, the backend should fetch the content of the semantically relevant document chunks. | The backend retrieves the actual text content of the document chunks identified as most relevant by the semantic search.                                                                                   |
| **S4-R2** | Generate Basic AI Response  | As a developer, the system should generate a concise answer based on the retrieved context. | The retrieved document chunks (context) are used as input to a language model (e.g., Azure OpenAI Service - a simpler model) to generate a relevant answer to the user's query.                                  |
| **S4-R3** | Display AI Response in UI   | As a user, I want to see the AI's answer to my question based on the uploaded documents. | The AI-generated response is displayed in the chat interface on the frontend, clearly presented to the user.                                                                                             |
| **S4-R4** | Simple Chat History (Session) | As a user, I want to see a history of my questions and the AI's responses within the current session. | The user's queries and the AI's responses are displayed chronologically in the chat interface during the current session. This history is not persisted across different sessions for this PoC. |
